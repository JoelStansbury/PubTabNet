{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75aa85e4-746c-4f1c-8cc9-b56551d69caf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d9e19-0232-41e5-b5e7-ade29052eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af9dc6-f577-444e-beae-e89d7108dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract as tess\n",
    "from PIL import Image\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb86a59-bf79-446e-9f3b-5320fba21fd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098f0d6-2b46-443d-9c61-a7cee2717ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r\"C:\\Users\\stans\\Documents\\Projects\\Datasets\\pubtabnet.tar\\pubtabnet\\pubtabnet\")\n",
    "test_dir = data_dir / \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa1428-a472-4d8e-b314-2493ce9c27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(test_dir.glob(\"*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf0f77-bb0e-436e-a73b-852952113aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"PubTabNet_2.0.0.jsonl\", \"r\", encoding=\"utf8\") as f:\n",
    "    json_list = list(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891769b-2f5c-49bb-89aa-d99569766179",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_index_map = {}\n",
    "\n",
    "for i, json_str in enumerate(json_list):\n",
    "    result = json.loads(json_str)\n",
    "    fname_index_map[result[\"filename\"]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57937fa9-4d65-4804-815b-6405172d780a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Utils\n",
    "Utility functions for interacting with the PubTabNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868a835-8ed7-41eb-8bd6-951814357023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Y(i):\n",
    "    fname = files[i]\n",
    "    i = fname_index_map[fname.parts[-1]]\n",
    "    return json.loads(json_list[i])\n",
    "\n",
    "def X(i):\n",
    "    return Image.open(files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245392b-1725-44a0-831c-3f507addea93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Image Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32e4ec-e1a8-4627-91c3-778f0f09901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(im, scale):\n",
    "    return im.resize((int(x*scale) for x in im.size))\n",
    "\n",
    "\n",
    "COLORS = {\n",
    "    'black':(0,0,0),\n",
    "    'red':(150,0,0),\n",
    "    'green':(0,150,0),\n",
    "    'blue':(0,0,150)\n",
    "}\n",
    "\n",
    "def draw(im, bbox, color='black'):\n",
    "    im = np.array(im)  # in case it is in PIL format\n",
    "    x,y,w,h = bbox\n",
    "    W,H,_ = im.shape\n",
    "    \n",
    "    if isinstance(color, str):\n",
    "        color = COLORS[color]\n",
    "    \n",
    "    pt1 = (x, y)\n",
    "    pt2 = (x+w, y+h)\n",
    "    return cv2.rectangle(im, pt1=pt1, pt2=pt2,\n",
    "        color=color, thickness=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd262fd-7b5a-4b6c-9512-6f920660066f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tesseract Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a88b8-f359-4e5a-a969-93e11d602973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tessdata_to_df(tessdata, keep_garbage=False):\n",
    "    \"\"\"Ingests a string repr of tesseract output and spits out a dataframe\"\"\"\n",
    "    rows = [r.split(\"\\t\") for r in tessdata.split(\"\\n\")[:-1]]\n",
    "    h = rows[0]\n",
    "    rows = rows[1:]\n",
    "        \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.columns = h\n",
    "    \n",
    "    # set types\n",
    "    dtypes = [int]*11 + [str]\n",
    "    for c,t in zip(df.columns, dtypes):\n",
    "        df[c] = df[c].values.astype(t)\n",
    "    \n",
    "    if not keep_garbage:\n",
    "        df = df[[x.strip() != \"\" for x in df[\"text\"]]]\n",
    "        df = df[df[\"conf\"] > 0].reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fit_bboxes_to_text(im, tessdata):\n",
    "    \"\"\"\n",
    "    Tesseract bboxes sometimes have very wide margins on them. This is bad for the purpose\n",
    "    of determining the grid that defines the layout.\n",
    "    Shrinks each side of the bbox until ~8% of the darkness is lost.\n",
    "    \n",
    "    im <PIL.Image or np.array()>: image used for cropping out the boxes defined in tessdata\n",
    "    \n",
    "    tessdata <Pandas.DataFrame>: Should be a dataframe with columns [\"left\",\"top\",\"width\",\"height\"]\n",
    "        as is returned by tessdata_to_df\n",
    "    \"\"\"\n",
    "    df_left = tessdata[\"left\"].values\n",
    "    df_top = tessdata[\"top\"].values\n",
    "    df_width = tessdata[\"width\"].values\n",
    "    df_height = tessdata[\"height\"].values\n",
    "    \n",
    "    im = np.array(im).sum(axis=2)\n",
    "    im = im / im.max()\n",
    "    im = abs(im - 1)\n",
    "    for i, bbox in enumerate(tessdata[['left', 'top', 'width', 'height']].values):\n",
    "        x,y,w,h = bbox\n",
    "        cropped = im[y:y+h, x:x+w]\n",
    "        \n",
    "        v_sum = cropped.sum(axis=1)\n",
    "        h_sum = cropped.sum(axis=0)\n",
    "        \n",
    "        top = 0\n",
    "        while sum(v_sum[top:]) > sum(v_sum)*0.98 and top < len(v_sum)-3:\n",
    "            top += 1\n",
    "            \n",
    "        bottom = len(v_sum)\n",
    "        while sum(v_sum[top:bottom]) > sum(v_sum)*0.96 and bottom > top+2:\n",
    "            bottom -= 1\n",
    "            \n",
    "            \n",
    "        left = 0\n",
    "        while sum(h_sum[left:]) > sum(h_sum)*0.98 and left < len(h_sum)-3:\n",
    "            left += 1\n",
    "            \n",
    "        right = len(h_sum)\n",
    "        while sum(h_sum[left:right]) > sum(h_sum)*0.96 and right > left+2:\n",
    "            right -= 1\n",
    "        \n",
    "        df_left[i] = x + left\n",
    "        df_top[i] = y + top\n",
    "        df_width[i] = right-left\n",
    "        df_height[i] = bottom-top\n",
    "        \n",
    "    df = tessdata.copy()\n",
    "    df[\"left\"] = df_left\n",
    "    df[\"top\"] = df_top\n",
    "    df[\"width\"] = df_width\n",
    "    df[\"height\"] = df_height\n",
    "    return df\n",
    "\n",
    "\n",
    "def im_to_data(im):\n",
    "    tessdata = tess.image_to_data(im, config=\"--psm 1\")\n",
    "    return tessdata_to_df(tessdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e690a-70c1-4b7a-93e2-dda3934a4701",
   "metadata": {},
   "source": [
    "## Cell Detection by OCR Bbox\n",
    "Tesseract's `image_to_data` function returns all detected words and their bounding boxes.<br>\n",
    "The following process determines if two tokens are part of the same cell based entirely on proximity.<br> \n",
    "After which, the bbox of each cell can be determined and finally the table grid\n",
    "can be fit to the cell boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb430d87-3b17-41f5-ae4c-0477820d3c57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Combine Tokens into Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de57cf-f430-436d-98a7-6467bb0be4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_tokens(df, im=None, direction=\"Both\", v=0):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    im_cp = im\n",
    "    assert isinstance(direction, str)\n",
    "    scale_y = 2\n",
    "    median_font_height = df[\"height\"].median()\n",
    "    eps_multiplier = 1\n",
    "    \n",
    "    model = DBSCAN(\n",
    "        eps=median_font_height * eps_multiplier,  # TODO: gridsearch the multiple for this\n",
    "        min_samples=2  # used to connect two tokens into the same cell\n",
    "    )\n",
    "    \n",
    "    # if v > 1:   \n",
    "    #     # draw a green box around detected token groups\n",
    "    #     for i, bbox in enumerate(df[['left', 'top', 'width', 'height']].values):\n",
    "    #         x,y,w,h = bbox\n",
    "    #         im = draw(im, bbox, 'blue')\n",
    "    \n",
    "    points = []\n",
    "    tokens = []\n",
    "    for i, bbox in enumerate(df[['left', 'top', 'width', 'height']].values):\n",
    "        x,y,w,h = bbox\n",
    "        \n",
    "        y = y*scale_y\n",
    "        tokens += [i]*8  # the next 8 points correspond to token[i]\n",
    "        \n",
    "        points.append([x, y+h/2])  # veritcally centered, left\n",
    "        points.append([x+w, y+h/2])  # vertically centerd, right\n",
    "        points.append([x+w/2, y])  # horizontally centered, top\n",
    "        points.append([x+w/2, y+h])  # horizontally centerd, bottom\n",
    "        points.append([x, y])  # top left\n",
    "        points.append([x, y+h])  # bottom left\n",
    "        points.append([x+w, y])  # top right\n",
    "        points.append([x+w, y+h])  # bottom right\n",
    "        \n",
    "    if v > 1:\n",
    "        assert im is not None\n",
    "        \n",
    "        # draw a red dot to show the points of each token\n",
    "        im = np.array(im)  # ensure cv2 format\n",
    "        for p in points:\n",
    "            x,y = int(p[0]), int(p[1]/scale_y)\n",
    "            im[y-2:y+2,x-2:x+2] = [255,0,0]\n",
    "    \n",
    "    groups = model.fit_predict(points)\n",
    "    \n",
    "    if v > 1:\n",
    "        # draw a blue line between connected dots\n",
    "        for i in range(max(groups)+1):\n",
    "            last = None\n",
    "            for j in [x for x in range(len(groups)) if groups[x] == i]:\n",
    "                if last:\n",
    "                    p1 = int(points[last][0]), int(points[last][1]/scale_y)\n",
    "                    p2 = int(points[j][0]), int(points[j][1]/scale_y)\n",
    "                    im = cv2.line(\n",
    "                        im,\n",
    "                        p1,\n",
    "                        p2,\n",
    "                        color=(0,0,255),\n",
    "                        thickness=2,\n",
    "                    )\n",
    "                last = j\n",
    "    \n",
    "    # shrink df to predicted cells\n",
    "    #\n",
    "    # I conceptualize this as connecting constructing multiple chains\n",
    "    # one link at a time in no particular order.\n",
    "    # The DBSCAN model told us which links are connected, now we need\n",
    "    # to construct all of the chains.\n",
    "    \n",
    "    # initialize the chain datastructure with all chains length 1\n",
    "    # corresponding to the tokens in the original dataframe\n",
    "    token_groups = defaultdict(list)\n",
    "    for i in range(len(df)):\n",
    "        token_groups[i].append(i)\n",
    "    \n",
    "    ## connecting the links\n",
    "    ### iterate through the detected groups and connect chains together\n",
    "    for i in range(max(groups)+1):\n",
    "        idxs = list(set([tokens[x] for x in range(len(groups)) if groups[x] == i]))\n",
    "        root = idxs[0]\n",
    "        \n",
    "        visited = set()\n",
    "        if isinstance(token_groups[root], int):\n",
    "            root = token_groups[root]\n",
    "            \n",
    "        assert isinstance(token_groups[root], list)\n",
    "        \n",
    "        for j in idxs[1:]:\n",
    "            children = token_groups[j]\n",
    "            if isinstance(children, int):\n",
    "                children = token_groups[children]\n",
    "            \n",
    "            assert isinstance(children, list)\n",
    "            root_children = token_groups[root] + children\n",
    "            for c in children:\n",
    "                token_groups[c] = root\n",
    "            token_groups[root] = root_children\n",
    "            \n",
    "            \n",
    "    rows = []\n",
    "    for key, val in list(token_groups.items()):\n",
    "        if isinstance(val,list):\n",
    "            t_pos = list(zip(df[\"text\"][val], df[\"left\"][val], df[\"top\"][val]))\n",
    "            \n",
    "            # sort tokens by y (at resolution of font height), break ties by x (at same res)\n",
    "            t_pos.sort(\n",
    "                key = lambda x: (\n",
    "                    x[2] // median_font_height,\n",
    "                    x[1] // median_font_height\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            text = \" \".join([x[0] for x in t_pos])\n",
    "            \n",
    "            left = min(df[\"left\"][val])\n",
    "            right = max(df[\"left\"][val] + df[\"width\"][val])\n",
    "            width = right - left\n",
    "            \n",
    "            top = min(df[\"top\"][val])\n",
    "            bottom = max(df[\"top\"][val] + df[\"height\"][val])\n",
    "            height = bottom - top\n",
    "            \n",
    "            rows.append({\n",
    "                \"left\": left,\n",
    "                \"top\": top,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"text\": text,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    if v > 1:   \n",
    "        # draw a green box around detected token groups\n",
    "        for i, bbox in enumerate(df[['left', 'top', 'width', 'height']].values):\n",
    "            x,y,w,h = bbox\n",
    "            im = draw(im, bbox, 'green')\n",
    "        \n",
    "    if v > 1:\n",
    "        display(Image.fromarray(im))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee94e13-1ae3-476d-ba00-75888314c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = scale(X(96), 3)\n",
    "df = im_to_data(im)\n",
    "df = fit_bboxes_to_text(im, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dfaf6-8b8c-4bbd-a99b-36feca6b4c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = group_tokens(df, im, v=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e150bb-c82f-475d-a705-54fda4952d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7d213-32c1-4b04-a08c-28d2f583bbc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fit Grid to Cell Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1508d1c-3d87-4c7f-9830-f676c1935850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_detect(\n",
    "    im,\n",
    "    margin=0,\n",
    "    v_thresh=0.1,\n",
    "    h_thresh=0.2,\n",
    "    v=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    im <PIL.Image or imarray>: Image of a table\n",
    "    \n",
    "    margin <int> (0): Number of pixels to shrink each token bbox for the purpose\n",
    "        of determining the grid.\n",
    "        \n",
    "    v_thresh <float> (0.1): Threshold for considering a row of pixels to be considered\n",
    "        a vertical boundary in the grid. Higher values mean fewer rows.\n",
    "        \n",
    "    h_thresh <float> (0.1): Threshold for considering a column of pixels to be considered\n",
    "        a horizontal boundary in the grid. Higher values mean fewer columns.\n",
    "    \n",
    "    v <int> (0): Verbose, 0-3. Show various stages of progress.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use Tesseract to find all words\n",
    "    df = im_to_data(im)\n",
    "    df = fit_bboxes_to_text(im, df) # try to remove any extraneous whitespace from the bbox\n",
    "    df = group_tokens(df, im, v=0) # spacially group bboxes into cells using DBSCAN\n",
    "        \n",
    "    # create a word mask from tesseract bboxes\n",
    "    mask = np.zeros(im.size)\n",
    "    for bbox in df[['left', 'top', 'width', 'height']].values:\n",
    "        x,y,w,h = bbox\n",
    "        mask[x+margin:x+w-margin,y+margin:y+h-margin]=1\n",
    "        \n",
    "    # mask=np.array(im).sum(axis=2).T  # use raw image instead of textboxes\n",
    "    # mask=mask/mask.max()\n",
    "    # mask-=1\n",
    "    # mask = abs(mask)\n",
    "\n",
    "    v_density = mask.sum(axis=0)/max(mask.sum(axis=0))\n",
    "    h_density = mask.sum(axis=1)/max(mask.sum(axis=1))\n",
    "\n",
    "\n",
    "    grid_y = []\n",
    "    y=0\n",
    "    out=True\n",
    "    for y,val in enumerate(v_density):\n",
    "        if val>v_thresh and out:\n",
    "            out=False\n",
    "            grid_y.append([y])\n",
    "        if not val>v_thresh and not out:\n",
    "            grid_y[-1].append(y)\n",
    "            out = True\n",
    "    \n",
    "    grid_x = []\n",
    "    x=0\n",
    "    out=True\n",
    "    for x,val in enumerate(h_density):\n",
    "        if val>h_thresh and out:\n",
    "            out = False\n",
    "            grid_x.append([x])\n",
    "        if not val>h_thresh and not out:\n",
    "            grid_x[-1].append(x)\n",
    "            out = True\n",
    "    \n",
    "    grid = []\n",
    "    for y in grid_y:\n",
    "        y1,y2 = y\n",
    "        for x in grid_x:\n",
    "            x1,x2 = x\n",
    "            grid.append([x1,y1,x2-x1,y2-y1])\n",
    "    \n",
    "    if v > 0:\n",
    "        for bbox in grid:\n",
    "            im = draw(im, bbox, 'red')\n",
    "    if v > 1:\n",
    "        fig, axs = plt.subplots(2,2)\n",
    "        axs[1,0].imshow(mask.T)\n",
    "        axs[1,0].xaxis.set_visible(False)\n",
    "        axs[1,0].yaxis.set_visible(False)\n",
    "        axs[1,1].plot(v_density, np.arange(mask.shape[1],0,-1))\n",
    "        axs[1,1].xaxis.set_visible(False)\n",
    "        axs[1,1].yaxis.set_visible(False)\n",
    "        axs[0,0].plot(h_density)\n",
    "        axs[0,0].xaxis.set_visible(False)\n",
    "        axs[0,0].yaxis.set_visible(False)\n",
    "        axs[0,1].imshow(im)\n",
    "        axs[0,1].xaxis.set_visible(False)\n",
    "        axs[0,1].yaxis.set_visible(False)\n",
    "        plt.show()\n",
    "    \n",
    "    if v > 2:\n",
    "        plt.imshow(mask.T)\n",
    "        plt.show()\n",
    "    if v > 0:\n",
    "        display(Image.fromarray(im))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a6246-794c-4cff-b998-264f372d3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd877b10-dee3-4b79-8caa-b5b8b0849e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f9edc-90b0-48b8-a926-ba3707e4b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_num += 1\n",
    "grid_detect(scale(X(f_num), 3), v=3, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae3eca-3c58-4cb6-a637-78130e711ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d21fb1-46e9-478b-98f5-163cc2bd1370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1de49-0425-4929-bcb4-4c0fff87fd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd3346-b75f-44be-9242-6975fd4a09ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad96dcb-dc82-4839-9155-ce333758366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25b18f-dda2-464d-b206-227f64dc92aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(96), 3), v=3, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16c1aa-cfa3-4b32-903b-9c15be164a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(82), 2), v=3, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b01fa4-9501-4fde-a83b-7e5f2a727759",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(80), 2), v=3, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17304411-2d7c-4d41-978d-854d77a8734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(70), 2), v=3, margin=-3, v_thresh=0, h_thresh=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17f4cb-8ea1-482a-a5ee-3de5a58e14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(48), 2), v=3, margin=-5, v_thresh=0, h_thresh=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdbd4a6-1fb0-4e87-9a1d-ea4873d2e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_detect(scale(X(64), 3), v=3, margin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d39a36-f741-4394-aa85-c269bbcb8ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb9a87-fe09-4ec2-bed7-a7292d9e9208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abba45b-377d-4a2e-94b7-9add2ac126c9",
   "metadata": {},
   "source": [
    "## Cell Detection by Color\n",
    "More or less the same idea as above except that the cell areas are much more noisy.<br>\n",
    "In this process we rely entirely on the pixel color values to determine where the cells are (no OCR needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbeb627-ee01-4d88-ad21-2e3b6d799441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d0887-f307-4647-84b6-8fb94a7bf2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2f15f-8dbd-4824-9596-98883b4250b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4253b4-3ecc-49fe-ad11-a52b6d853bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imarr1 = np.array(im)\n",
    "for cell in Y(f_num)['html']['cells']:\n",
    "    if 'bbox' in cell:\n",
    "        # make sure bbox is not in x1,y1,x2,y2\n",
    "        # that would explain the wierd sizes\n",
    "        imarr1 = draw(imarr1, cell['bbox'], 'green')\n",
    "\n",
    "imarr2 = np.array(scaled_im)\n",
    "for bbox in df[['left', 'top', 'width', 'height']].values:\n",
    "    \n",
    "    imarr2 = draw(imarr2, bbox, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b2419-4d5c-4767-bdda-f913084bdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale(Image.fromarray(imarr1),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fca126-5653-4f0c-b220-881410ad1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(imarr2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
